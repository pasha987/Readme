Q1-
# Lemmatization using NLTK

import nltk
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

# Download required datasets (only first time)
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

lemmatizer = WordNetLemmatizer()

text = "The leaves on the trees were falling and the children were playing with the fallen leaves."

tokens = word_tokenize(text)

print("Original Words:")
print(tokens)

print("\nLemmatized Words:")
for word in tokens:
    print(word, "=>", lemmatizer.lemmatize(word))

Q2-
from collections import deque

# Graph derived from the diagram
graph = {
    1: [2, 4],
    2: [3],
    3: [2, 4, 6, 5],
    4: [1],
    5: [3, 8, 7],
    6: [8],
    7: [8],
    8: []
}

def bfs(start, goal):
    visited = set()
    queue = deque([[start]])  # store paths
    
    while queue:
        path = queue.popleft()
        node = path[-1]

        if node == goal:
            return path

        if node not in visited:
            visited.add(node)

            for neighbor in graph[node]:
                new_path = list(path)
                new_path.append(neighbor)
                queue.append(new_path)

    return None


start_node = 1
goal_node = 8

result = bfs(start_node, goal_node)

print("BFS Path from", start_node, "to", goal_node, ":")
print(result)
